{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRO91ndzIOu5"
   },
   "source": [
    "# Bag Of Words Topic Modeling and Recommender for Ted Talks - JBCS\n",
    " - Summer K. Rankin "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uUnwZ5kZIOu9"
   },
   "source": [
    "once the text has been cleaned, we move onto the next steps\n",
    "        - 1. Vectorize \n",
    "        - 2. Topic modeling\n",
    "        - 3. Visualization\n",
    "        - 4. Recommender (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfJWdiQsIOu_"
   },
   "source": [
    "# Load the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-15T20:08:30.547215Z",
     "start_time": "2017-11-15T20:08:28.639903Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3CeRpnv3IOvB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import nltk, re, pickle, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation,  TruncatedSVD, NMF\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing  import  StandardScaler\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyLDAvis, pyLDAvis.sklearn\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fc7XJO0ZYh4D"
   },
   "source": [
    "# Import the cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-15T20:08:32.451011Z",
     "start_time": "2017-11-15T20:08:31.800142Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tvwZHlqwIOvN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/ext200/opt/anaconda3/envs/nlpBase/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/cleaned_talks.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3803febb1ce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/cleaned_talks.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpicklefile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcleaned_talks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpicklefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/cleaned_talks.pkl'"
     ]
    }
   ],
   "source": [
    "with open('./data/cleaned_talks.pkl', 'rb') as picklefile:\n",
    "    cleaned_talks = pickle.load(picklefile)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xRVKlSnd4WUB"
   },
   "source": [
    "# 1 Vectorization\n",
    "Vectorization is the important step of turning our words into numbers. There are 2 common methods: count vectorizer, tf-idf. This function takes each word in each document and counts the number of times the word appears. You end up with each word (and n-gram) as your columns and each row is a document, so the data is the frequency of each word in each document. As you can imagine, there will be a large number of zeros in this matrix; we call this a sparse matrix. https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "tf-IDF\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer\n",
    "\n",
    "----\n",
    "\n",
    "For this tutorial the tokenization and vectorization gets bundled together because we are using skleanrn's feature extraction functions. This means we will set the parameters of these functions to tokenize the way we want, include n-grams, and set thresholds for max or min document frequency of a term. https://towardsdatascience.com/hacking-scikit-learns-vectorizers-9ef26a7170af\n",
    "\n",
    "- takes us from words to numbers \n",
    "- create the document-term matrix which is the basis for all modeling\n",
    "    - row = document, column = word or n-gram, data = word's weight for that document\n",
    "- we will vectorize in 2 ways \n",
    "    1. counting the frequency of each term in each document (**CountVectorizer**)\n",
    "    2. counting the frequency of each term in each document and weighting by the number of times the term appears in the corpus. Term Frequency * Inverse Document Frequency (**TfidfVectorizer**)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JjhVfWQbIOvX"
   },
   "source": [
    "# 1.1 Count Vectorize \n",
    "+ Using Sklearn algorithms with text data\n",
    "+ CountVectorizer: Convert a collection of text documents to a matrix of token counts \n",
    "+ This implementation produces a sparse representation\n",
    "+  **CountVectorizer** is a class; so **vectorizer** below represents an instance of that object\n",
    "+ note that we can also **lowercase** , remove **stopwords** and search for a certain pattern **token_pattern** (i.e. letters only) by using the parameters of this function. \n",
    "+ a specific vocabulary can also be passed to this function. \n",
    "+ for more info about the many parameters, see the sklearn docs. \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "CountVectorizer is a class; so `vectorizer` below represents an instance of that object.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "colab_type": "code",
    "id": "eHvDuH-VNipZ",
    "outputId": "502efa9c-5475-49f5-fb93-adef41bb684f"
   },
   "outputs": [],
   "source": [
    "c_vectorizer = CountVectorizer(max_df = 0.6, \n",
    "                             max_features=2000)\n",
    "\n",
    "# call `fit` to build the vocabulary and calculate the weights\n",
    "c_vectorizer.fit(cleaned_talks)\n",
    "\n",
    "# finally, call `transform` to apply the weights and convert text to a bag of words\n",
    "count_vect_data = c_vectorizer.transform(cleaned_talks)\n",
    "\n",
    "# to view the document-term matrix, we can transpose back to a dense array\n",
    "pd.DataFrame(data = count_vect_data.toarray(), columns=sorted(c_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing with sklearn\n",
    "Parameters in the sklearn vectorizer class that can be used to do the cleaning and normalization of text (can be used as an alternative to what we did in the first notebook if the processing is light:<br>\n",
    "* `analyzer=word`: Tokenize by word\n",
    "* `ngram_range=(1,3)`: Keep all 1 and 2, and 3-word grams\n",
    "* `stop_words='english'`: Remove all English stop words\n",
    "* `token_pattern=\\\\b[a-z][a-z]+\\\\b`: Match all tokens with 2 or more (strictly) alphabet characters\n",
    "\n",
    "TODO: import the original ted_talks and pre-process them using skleanrn methods instead of writing your own function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "talks = #TODO: import original (not cleaned_ talks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vectorizer_skl = CountVectorizer(##TODO: invoke cleaning functions from the CountVectorizer class to preprocess\n",
    "                                    max_df = 0.6, \n",
    "                                    max_features=2000)\n",
    "\n",
    "# call `fit` to build the vocabulary and calculate the weights\n",
    "c_vectorizer_skl.fit(##TODO: import the original data)\n",
    "\n",
    "# finally, call `transform` to apply the weights and convert text to a bag of words\n",
    "count_vect_data_skl = c_vectorizer_skl.transform(##TODO: use imported original talks)\n",
    "\n",
    "# to view the document-term matrix, we can transpose back to a dense array\n",
    "pd.DataFrame(data = count_vect_data_skl.toarray(), columns=sorted(c_vectorizer_skl.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LgwMTjtNIOvs"
   },
   "source": [
    "# 1.2 Tf-idf (term frequency inverse document frequency)\n",
    "+ gives more weight to less frequent terms \n",
    "\n",
    "by calculating a weight for each term $j$ in each document $i$ \n",
    "\n",
    "$$\n",
    "w_{i,j}= tf_{i,j} x \\log\\frac{N}{df_j}\n",
    "$$\n",
    "\n",
    "$N$ = total documents\n",
    "$j$ = term\n",
    "$i$ = document\n",
    "$df$ = document frequency\n",
    "$tf$ = term frequency\n",
    "\n",
    "frequency of the $j$th term in the $i$th document multiplied by the log of the total documents divided by the number of documents in the corpus containing the $j$th term. \n",
    "\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T02:12:53.508282Z",
     "start_time": "2017-11-10T02:11:40.354134Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "GBgRQBsYIOvu"
   },
   "outputs": [],
   "source": [
    "t_vectorizer = TfidfVectorizer(#TODO: choose the parameters you want to use to process and vectorize the data)\n",
    "\n",
    "\n",
    "# call `fit` to build the vocabulary and calculate weights\n",
    "t_vectorizer.fit(#TODO: choose whether to use the original talks or cleaned talks)\n",
    "\n",
    "# finally, call `transform` to convert text to a bag of words\n",
    "tfidf_data = t_vectorizer.transform(#TODO: choose whether to use the original talks or cleaned talks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "colab_type": "code",
    "id": "XzXTTSrIcleZ",
    "outputId": "5686768c-7729-4b52-8f51-19d6b9cd997f"
   },
   "outputs": [],
   "source": [
    "# view a dense representation of the document-term matrix\n",
    "pd.DataFrame(tfidf_data.toarray(), columns=t_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0qthRkfO4R_M"
   },
   "source": [
    "# 2 Topic modeling \n",
    "Use the document term matrix created with vectorization, to create a latent space and find the words that tend to ocurr together\n",
    "\n",
    "We will use LDA Latent Dirichlet Allocation here (there are several methods, NMF, SVD)\n",
    "\n",
    "This will reduce the data from thousands of terms (dimensions) to 20 topics. (Dimensionality Reduction)\n",
    "\n",
    "Creates a latent space that is X dimensions.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WY1cESM2IOv1"
   },
   "source": [
    "# LDA Latent Dirichlet Allocation\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-15T20:06:54.880541Z",
     "start_time": "2017-11-15T20:06:54.812697Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "d4lXxWUFIOv5"
   },
   "outputs": [],
   "source": [
    "def topic_mod(vectorizer, vect_data, topics=20, iters=5, no_top_words=50):\n",
    "    \n",
    "    \"\"\" use Latent Dirichlet Allocation to get topics\"\"\"\n",
    "\n",
    "    mod = LatentDirichletAllocation(n_components=topics,\n",
    "                                    max_iter=iters,\n",
    "                                    random_state=42,\n",
    "                                    learning_method='online',\n",
    "                                    n_jobs=-1)\n",
    "    \n",
    "    mod_dat = mod.fit_transform(vect_data)\n",
    "    \n",
    "    \n",
    "    # to display a list of topic words and their scores \n",
    "    \n",
    "    def display_topics(model, feature_names, no_top_words):\n",
    "        for ix, topic in enumerate(model.components_):\n",
    "            print(\"Topic \", ix)\n",
    "            print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]) + '\\n')\n",
    "    \n",
    "    display_topics(mod, vectorizer.get_feature_names() , no_top_words)\n",
    "\n",
    "    \n",
    "    return mod, mod_dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bmmdftaFXaZ_"
   },
   "source": [
    "#### TODO: Calculate the topic modeling using both of the count vectorized methods and tfidf to compare differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bmmdftaFXaZ_"
   },
   "outputs": [],
   "source": [
    "# Count Vectorizer on cleaned talks \n",
    "count_lda_model, count_lda_data = topic_mod(c_vectorizer, \n",
    "                            count_vect_data, \n",
    "                            topics=20, \n",
    "                            iters=10, \n",
    "                            no_top_words=15)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer on raw talks \n",
    "count_raw_lda_model, count_raw_lda_data = topic_mod(c_vectorizer_skl,\n",
    "                                                   #TODO\n",
    "                                    \n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer on cleaned talks \n",
    "tfidf_lda_model, tfidf_lda_data = topic_mod(t_vectorizer, \n",
    "                                            tfidf_data,\n",
    "                                            topics=20,\n",
    "                                            iters=10,\n",
    "                                            no_top_words=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer on raw talks \n",
    "tfidf_raw_lda_model, tfidf_raw_lda_data = topic_mod("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WA-bPJRAIOwq"
   },
   "source": [
    "# 3 Visualization  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "arFh_8_s4m_Y"
   },
   "source": [
    "# 3.1 View distribution of topics with pyLDAvis \n",
    "+ plot the first 2 components from the topic modeling (LDA). \n",
    "+ Not really the best way to look at clusters, but a good place to start and a very nice way to present data to clients\n",
    "\n",
    "TODO: also plot the visualization for the raw vs. cleaned (by you) \n",
    "and count vectorizled vs. tf-idf vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-15T20:28:17.621582Z",
     "start_time": "2017-11-15T20:28:09.867331Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "fyYrDYoFIOwu",
    "outputId": "87626c1b-551b-41a1-976e-7773ada9c0a3"
   },
   "outputs": [],
   "source": [
    "# Setup to run in Jupyter notebook\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-15T20:28:17.621582Z",
     "start_time": "2017-11-15T20:28:09.867331Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "fyYrDYoFIOwu",
    "outputId": "87626c1b-551b-41a1-976e-7773ada9c0a3"
   },
   "outputs": [],
   "source": [
    "# to plot the self cleaned count vectorized data \n",
    "\n",
    "# Create the visualization\n",
    "vis = pyLDAvis.sklearn.prepare(count_lda_model, count_vect_data, c_vectorizer, sort_topics=False, mds='mmds')\n",
    "\n",
    " # can export as a standalone HTML web page\n",
    "pyLDAvis.save_html(vis, 'lda_visual.html')\n",
    "\n",
    "# # Let's view it!\n",
    "display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the tfidf vectorized self cleaned data\n",
    "\n",
    "vis = pyLDAvis.sklearn.prepare(tfidf_lda_model, tfidf_data, t_vectorizer, sort_topics=False, mds='mmds')\n",
    "\n",
    " # can export as a standalone HTML web page\n",
    "pyLDAvis.save_html(vis, 'lda_visual.html')\n",
    "\n",
    "# # Let's view it!\n",
    "display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ART of Topic Modeling\n",
    "\n",
    "#### TODO: Now, go back to your favorite LDA model and change the number of topics. \n",
    "YOu may want to also run the pyLDAvis to view the results easier\n",
    "What happens to the topics when you reduce the number of topics  to 5?\n",
    "What happens when you increase the number of topics to 100? \n",
    "Play with the number to get an optimum number of topics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling results per document\n",
    "Let's look at the probability scores assigned to a single document. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a document's text \n",
    "talks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results from one document \n",
    "tfidf_lda_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_lda_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-15T20:25:46.602136Z",
     "start_time": "2017-11-15T20:25:46.598326Z"
    },
    "colab_type": "text",
    "id": "fwHOYf2aIOwF"
   },
   "source": [
    "# 3.2 Assign a topic to each document\n",
    "\n",
    "+ for each document, assign the topic (column) with the  highest score from the LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-15T20:25:00.419658Z",
     "start_time": "2017-11-15T20:25:00.388311Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "W9Bi_CGyIOwI"
   },
   "outputs": [],
   "source": [
    "topic_index = np.argmax(lda_data, axis=1)\n",
    "topic_index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Yrdyk1v6Ws-"
   },
   "source": [
    " # 3.3 Assign labels to topics  (More ART)\n",
    "TODO: replace the maximum topic number with a label chosen by you.  \n",
    "Try to use the top terms from each topic to give it a label.   \n",
    "You will need to have the same number of names as you do in your optimal LDA.     \n",
    " If you have a LOT of topics, you can just leave them as numbers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T22:16:11.778984Z",
     "start_time": "2017-11-13T22:16:11.624198Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "MZqdbTMqIOwR"
   },
   "outputs": [],
   "source": [
    "topic_names = pd.DataFrame(topic_index)\n",
    "\n",
    "topic_names[topic_names==0] = \"family\"\n",
    "topic_names[topic_names==1] = \"agriculture\"\n",
    "topic_names[topic_names==2] = \"2\"\n",
    "topic_names[topic_names==3] = \"3\"\n",
    "topic_names[topic_names==4] = \"4\"\n",
    "topic_names[topic_names==5] = \"\"\n",
    "topic_names[topic_names==6] = \"\"\n",
    "topic_names[topic_names==7] = \"\"\n",
    "topic_names[topic_names==8] = \"\"\n",
    "\n",
    "topic_names[topic_names==9] = \"\"\n",
    "topic_names[topic_names==10] = \"\"\n",
    "topic_names[topic_names==11] = \"\"\n",
    "\n",
    "topic_names[topic_names==12] = \"\"\n",
    "topic_names[topic_names==13] = \"climate, energy\"\n",
    "\n",
    "topic_names[topic_names==14] = \"politics\"\n",
    "topic_names[topic_names==15] = \"\"  \n",
    "topic_names[topic_names==16] = \"\"\n",
    "topic_names[topic_names==17] = \"\"\n",
    "topic_names[topic_names==18] = \"\"\n",
    "topic_names[topic_names==19] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T22:16:30.403758Z",
     "start_time": "2017-11-13T22:16:30.368886Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "VhEt8znVIOwb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FgnG9yjO1dJ9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iy1YLOKS1yFt"
   },
   "source": [
    "# 4. Recommender (optional)\n",
    "we will use the Ted Talk metadata to add some information to our recommender. \n",
    "\n",
    "# import original talks and metadata\n",
    "merge them on the 'url' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "colab_type": "code",
    "id": "mBjJsRug1dSi",
    "outputId": "2da4442b-f4d7-4234-d3ab-f3b909771727"
   },
   "outputs": [],
   "source": [
    "ted_trans = pd.read_csv('./data/transcripts.csv', encoding = \"UTF-8\")  \n",
    "ted_main = pd.read_csv('./data/ted_main.csv', encoding = \"UTF-8\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Tyiept22OuS"
   },
   "outputs": [],
   "source": [
    "ted_all = pd.merge(ted_trans, right=ted_main, on='url')\n",
    "ted_all.url = ted_all.url.astype('str',copy=False)\n",
    "\n",
    "ted_all.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T22:17:07.519083Z",
     "start_time": "2017-11-13T22:17:07.481396Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "mvw0Da3NIOwj"
   },
   "outputs": [],
   "source": [
    "def get_recommendations(target_doc, num_of_recs, topics, data, topic_model, vectorizer, topic_model_data):\n",
    "    \n",
    "    new_vec = topic_model.transform(\n",
    "        vectorizer.transform([target_doc]))\n",
    "    \n",
    "    nn = NearestNeighbors(n_neighbors=num_of_recs, metric='cosine', algorithm='brute')\n",
    "    nn.fit(topic_model_data)\n",
    "    \n",
    "    results = nn.kneighbors(new_vec)\n",
    "    \n",
    "    recommend_list = results[1][0]\n",
    "    scores = results[0]\n",
    "                       \n",
    "    ss = np.array(scores).flat\n",
    "    for i, resp in enumerate(recommend_list):\n",
    "        print('\\n--- ID ---\\n', + resp)\n",
    "        print('--- distance ---\\n', + ss[i])  \n",
    "        print('--- topic ---')\n",
    "        print(topics.iloc[resp,0])\n",
    "        print(data.iloc[resp,1])\n",
    "        print('--- teds tags ---')\n",
    "        print(data.iloc[resp,-3])\n",
    "        \n",
    "    return recommend_list, ss   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuDD5J5u1UYt"
   },
   "outputs": [],
   "source": [
    "rec_list, scores = get_recommendations(cleaned_talks[804], num_of_recs=10, topics=topic_names, data=ted_all,\n",
    "                                       topic_model=lda_model, vectorizer=c_vectorizer, topic_model_data=lda_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n9AE8sG44Rht"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hic3xHc841Jb"
   },
   "source": [
    "# 4.1 search and recommend similar documents\n",
    "We use a great library called fuzzywuzzy to find the titles that is most similar to a search term. then we use this as our target document for the recommendation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "Ic7iyyjC5IZ8",
    "outputId": "a9a336ab-a1e4-4c67-cd10-08c96d3037b8"
   },
   "source": [
    " #### You will need to install fuzzywuzzy in your conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "7Vws5xfs4Rmi",
    "outputId": "bd466379-2fa9-44f8-97da-51dde3bcf745"
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "search_term = \"computer science\"\n",
    "\n",
    "titles = ted_all['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xYq1ofsY4RrH"
   },
   "outputs": [],
   "source": [
    "tite, score, talk_ind = process.extractOne(search_term, titles, scorer=fuzz.token_set_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZfpdIc8f4p6c"
   },
   "outputs": [],
   "source": [
    "rec_list, scores = get_recommendations(cleaned_talks[talk_ind], num_of_recs=10, topics=topic_names, data=ted_all,\n",
    "                                       topic_model=lda_model, vectorizer=c_vectorizer, topic_model_data=lda_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of topic_modeling_ted_jbcs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
